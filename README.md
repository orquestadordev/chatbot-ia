# Chatbot Local

Repositorio para un chatbot local basado en Ollama. Actualmente solo incluye el backend Node.js encargado de exponer un endpoint SSE `/api/chat` que reenv√≠a tokens desde Ollama hacia el cliente.

````markdown
# Chatbot Local

Repositorio para un chatbot local basado en Ollama. Actualmente solo incluye el backend Node.js encargado de exponer un endpoint SSE `/api/chat` que reenv√≠a tokens desde Ollama hacia el cliente.

## Carpetas

- `backend/` ‚Äì API Node.js + TypeScript (Express) que orquesta peticiones a Ollama y transmite tokens v√≠a Server-Sent Events.
- `ui/` ‚Äì reservada para la interfaz futura (a√∫n no implementada).

## C√≥mo ejecutar el backend

```bash
cd backend
npm install
npm run dev
```

El servidor arrancar√° en `http://localhost:4000` (configurable con `PORT`).

## Estado actual

- ‚úÖ API `/api/chat` con validaci√≥n b√°sica, SSE y forward de streaming desde Ollama
- üöß Pendiente: construir la UI, agregar observabilidad y RAG

## Requisitos previos

- Node.js 18+
- Ollama instalado y corriendo manualmente con `ollama serve` en una terminal aparte (`http://127.0.0.1:11434`).
- Modelo `llama3` descargado localmente (`ollama pull llama3`).
- El backend **no** inicia Ollama autom√°ticamente: asegurate de que el servicio est√© arriba antes de `npm run dev`.

````
